{"cells":[{"cell_type":"markdown","metadata":{"id":"cNw3DLR9NqOt"},"source":["# 합성곱 신경망(Convolutional Neural Networks, CNNs)\n","\n","- 이미지 인식, 음성 인식 등에 자주 사용되는데,  \n","  특히, 이미지 인식 분야에서 거의 모든 딥러닝 기술에 사용\n","\n","<br>\n","\n","## 컨볼루션 신경망의 등장\n","- 1989년 얀 르쿤(Yann LeCun) 교수의 논문에서 발표\n","\n","  - 필기체 인식에서 의미가 있었지만 범용화하는데에는 무리\n","\n","- 1998년, \"Gradient-Based Learning Applied to Document Recognition\"이라는 논문에서 LeNet-5 제시\n","\n","- 합성곱 층(convolution layer), 풀링 층(pooling layer) 소개\n","  <br>\n","\n","  <img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n","  \n","  <center>[LeNet-5 구조]</center>\n","\n","  <sub>출처: https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"]},{"cell_type":"markdown","metadata":{"id":"jEwbDi16NtE0"},"source":["\n","## 완전연결계층과의 차이\n","- 완전연결계층(Fully-Connected Layer)은 이미지와 같은 데이터의 형상(3차원)을 무시함  \n","\n","- 모든 입력데이터를 동등하게 취급  \n","  즉, **데이터의 특징을 잃어버리게 됨**\n","\n","- 컨볼루션층(convolution layer)은 <u>**이미지 픽셀 사이의 관계를 고려**</u>\n","\n","- 완전연결계층은 공간정보를 손실하지만, 컨볼루션층은 공간정보를 유지  \n","  - 이미지와 같은 2차원(흑백) 또는 3차원(컬러)의 형상을 유지\n","\n","  - 공간정보를 유지하기 때문에 완전연결계층에 비해 적은 수의 파라미터를 요구\n"]},{"cell_type":"markdown","metadata":{"id":"Y46evOQHNukF"},"source":["## 컨볼루션 신경망 구조 예시\n","\n","<img src=\"https://www.oreilly.com/library/view/neural-network-projects/9781789138900/assets/c38754ca-f2ea-425a-b7a6-1fe0f2f5074e.png\" width=\"600\">\n","\n","<sub>출처: https://www.oreilly.com/library/view/neural-network-projects/9781789138900/8e87ad66-6de3-4275-81a4-62b54436bf16.xhtml</sub>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Wtb8UWyTNxp_"},"source":["## 합성곱 연산\n","- 필터(filter) 연산\n","  - 입력 데이터에 필터를 통한 어떠한 연산을 진행\n","  \n","  - **필터에 대응하는 원소끼리 곱하고, 그 합을 구함**\n","\n","  - 연산이 완료된 결과 데이터를 **특징 맵(feature map)**이라 부름\n","\n","- 필터(filter)\n","  - 커널(kernel)이라고도 칭함\n","  \n","  - 흔히 사진 어플에서 사용하는 '이미지 필터'와 비슷한 개념\n","\n","  - 필터의 사이즈는 \"거의 항상 홀수\"\n","    - 짝수이면 패딩이 비대칭이 되어버림\n","  \n","    - 왼쪽, 오른쪽을 다르게 주어야함\n","  \n","    - 중심위치가 존재, 즉 구별된 하나의 픽셀(중심 픽셀)이 존재\n","\n","  - 필터의 학습 파라미터 개수는 입력 데이터의 크기와 상관없이 일정  \n","    따라서, 과적합을 방지할 수 있음\n","\n","  <br>\n","  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/numerical_no_padding_no_strides.gif\">\n","\n","  <sub>출처: http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html</sub>\n","\n","\n","- 연산 시각화\n","  <img src=\"https://www.researchgate.net/profile/Ihab_S_Mohamed/publication/324165524/figure/fig3/AS:611103423860736@1522709818959/An-example-of-convolution-operation-in-2D-2.png\" width=\"500\">\n","\n","  <sub>출처: https://www.researchgate.net/figure/An-example-of-convolution-operation-in-2D-2_fig3_324165524</sub>\n","\n","\n","- 일반적으로, 합성곱 연산을 한 후의 데이터 사이즈는  \n","  ### $\\quad (n-f+1) \\times (n-f+1)$\n","    $n$: 입력 데이터의 크기  \n","    $f$: 필터(커널)의 크기\n","\n","\n","  <img src=\"https://miro.medium.com/max/1400/1*Fw-ehcNBR9byHtho-Rxbtw.gif\" width=\"400\">\n","\n","  <sub>출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>\n","  \n","  위 예에서 입력 데이터 크기($n$)는 5, 필터의 크기($k$)는 3이므로  \n","  출력 데이터의 크기는 $(5 - 3 + 1) = 3$\n"]},{"cell_type":"markdown","metadata":{"id":"5-ekDsJwN2Y-"},"source":["## 패딩(padding)과 스트라이드(stride)\n","- 필터(커널) 사이즈과 함께 **입력 이미지와 출력 이미지의 사이즈를 결정**하기 위해 사용\n","\n","- 사용자가 결정할 수 있음\n"]},{"cell_type":"markdown","metadata":{"id":"alV1bgcjN4Kc"},"source":["\n","### 패딩\n","- 입력 데이터의 주변을 특정 값으로 채우는 기법\n","  - 주로 0으로 많이 채움\n","\n","  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/arbitrary_padding_no_strides.gif\" width=\"300\">\n","\n","- 출력 데이터의 크기\n","  ### $\\quad (n+2p-f+1) \\times (n+2p-f+1)$\n","\n","  위 그림에서, 입력 데이터의 크기($n$)는 5, 필터의 크기($f$)는 4, 패딩값($p$)은 2이므로    \n","  출력 데이터의 크기는 ($5 + 2\\times 2 - 4 + 1) = 6$\n","\n","### 'valid' 와 'same'\n","- 'valid'\n","  - 패딩을 주지 않음\n","  - padding=0 (0으로 채워진 테두리가 아니라 패딩을 주지 않는다는 의미)\n","\n","- 'same'\n","  - 패딩을 주어 입력 이미지의 크기와 연산 후의 이미지 크기를 같게함\n","\n","  - 만약, 필터(커널)의 크기가 $k$ 이면,  \n","    패딩의 크기는 $p = \\frac{k-1}{2}$ (단, <u>stride=1)</u>"]},{"cell_type":"markdown","metadata":{"id":"zlZ7zG6ON85J"},"source":["\n","\n","### 스트라이드\n","- 필터를 적용하는 간격을 의미\n","\n","- 아래는 그림의 간격 2\n","\n","  <img src=\"http://deeplearning.net/software/theano_versions/dev/_images/no_padding_strides.gif\">\n"]},{"cell_type":"markdown","metadata":{"id":"LPcsND-0OCNm"},"source":["## 출력 데이터의 크기\n","\n","## $\\qquad OH = \\frac{H + 2P - FH}{S} + 1 $ \n","## $\\qquad OW = \\frac{W + 2P - FW}{S} + 1 $ \n","\n","- 입력 크기 : $(H, W)$\n","\n","- 필터 크기 : $(FH, FW)$\n","\n","- 출력 크기 : $(OH, OW)$\n","\n","- 패딩, 스트라이드 : $P, S$\n","\n","- (주의) \n","  - 위 식의 값에서 $\\frac{H + 2P - FH}{S}$ 또는 $\\frac{W + 2P - FW}{S}$가 정수로 나누어 떨어지는 값이어야 함\n","  - 만약, 정수로 나누어 떨어지지 않으면  \n","    패딩, 스트라이드값을 조정하여 정수로 나누어 떨어지게 해야함\n"]},{"cell_type":"markdown","metadata":{"id":"1x4UoMbF8jJ9"},"source":["## 풀링(Pooling)\n","\n","- 필터(커널) 사이즈 내에서 특정 값을 추출하는 과정"]},{"cell_type":"markdown","metadata":{"id":"lDiaO3XF8oC_"},"source":["### 맥스 풀링(Max Pooling)\n","- 가장 많이 사용되는 방법\n","\n","- 출력 데이터의 사이즈 계산은 컨볼루션 연산과 동일\n","## $\\quad OH = \\frac{H + 2P - FH}{S} + 1 $ \n","## $\\quad OW = \\frac{W + 2P - FW}{S} + 1 $ \n","\n","- 일반적으로 stride=2, kernel_size=2 를 통해  \n","  **특징맵의 크기를 <u>절반으로 줄이는 역할</u>**\n","\n","- 모델이 물체의 주요한 특징을 학습할 수 있도록 해주며,  \n","  컨볼루션 신경망이 이동 불변성 특성을 가지게 해줌\n","  - 예를 들어, 아래의 그림에서 초록색 사각형 안에 있는  \n","    2와 8의 위치를 바꾼다해도 맥스 풀링 연산은 8을 추출\n","\n","- 모델의 파라미터 개수를 줄여주고, 연산 속도를 빠르게 해줌\n","\n","  <br>\n","\n","  <img src=\"https://cs231n.github.io/assets/cnn/maxpool.jpeg\" width=\"600\">\n","\n","  <sub>출처: https://cs231n.github.io/convolutional-networks/</sub>"]},{"cell_type":"markdown","metadata":{"id":"4czHpHrW8qyb"},"source":["### 평균 풀링(Avg Pooling)\n","\n","- 필터 내의 있는 픽셀값의 평균을 구하는 과정\n","\n","- 과거에 많이 사용, 요즘은 잘 사용되지 않는다.\n","\n","- 맥스풀링과 마찬가지로 stride=2, kernel_size=2 를 통해  \n","  특징 맵의 사이즈를 줄이는 역할\n","\n","  <img src=\"https://www.researchgate.net/profile/Juan_Pedro_Dominguez-Morales/publication/329885401/figure/fig21/AS:707709083062277@1545742402308/Average-pooling-example.png\" width=\"600\">\n","\n","  <sub>출처: https://www.researchgate.net/figure/Average-pooling-example_fig21_329885401</sub>"]},{"cell_type":"markdown","metadata":{"id":"YkUkaiTKOpQa"},"source":["## 합성곱 연산의 의미"]},{"cell_type":"markdown","metadata":{"id":"3vqpxGe1Oqqt"},"source":["## 2차원 이미지에 대한 필터 연산 예시\n","  - 가장 자리 검출(Edge-Detection)\n","\n","  - 소벨 필터(Sobel Filter)\n","\n","    - Horizontal : 가로 방향의 미분을 구하는 필터 역할\n","\n","    - Vertical : 세로 방향의 미분을 구하는 필터 역할  \n","\n","  <img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT_ZRkuiCkv0ZEHFiyCp-7Y5bCL0liaYSQ4mg&usqp=CAU\" width=\"350\">\n","\n","  <sub>출처: https://www.cloras.com/blog/image-recognition/</sub>\n"]},{"cell_type":"markdown","metadata":{"id":"hwmDwRuWO60O"},"source":["## 3차원 데이터의 합성곱 연산\n","- **이미지는 3차원으로 구성**\n","  - (가로, 세로, 채널 수)\n","  - 채널 : RGB \n","\n","- 색상값의 정도에 따라 color색 결정\n","\n","  <img src=\"https://www.projectorcentral.com/images/articles/RGB-Explained-600.jpg\">\n","\n","  <sub>출처: https://www.projectorcentral.com/All-About-Bit-Depth.htm?page=What-Bit-Depth-Looks-Like</sub>\n","\n","### 아래의 이미지 확인은 참고사항"]},{"cell_type":"markdown","metadata":{"id":"UgT1V4z11xU8"},"source":["### 연산 과정\n","\n","- 각 채널마다 컨볼루션 연산을 적용\n","  - 3채널을 모두 합쳐서 '하나의 필터'라고 칭함  \n","    \n","  <img src=\"https://miro.medium.com/max/2000/1*8dx6nxpUh2JqvYWPadTwMQ.gif\" width=\"600\">\n","\n","<br>\n","\n","- 각각의 결과를 더함  \n","  \n","  <img src=\"https://miro.medium.com/max/2000/1*CYB2dyR3EhFs1xNLK8ewiA.gif\" width=\"600\">\n","\n","<br>\n","\n","- 더한 결과에 편향을 더함  \n","  <img src=\"https://miro.medium.com/max/588/1*RYYucIh3U-YFxrIkyQKzRw.gif\" width=\"300\">\n","\n","  <sub>출처: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1</sub>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NqRxcG4NeLVZ"},"source":["# 대표적인 CNN 모델 소개"]},{"cell_type":"markdown","metadata":{"id":"loGDkBaxd9O0"},"source":["## LeNet - 5\n","\n","<img src=\"https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n","  \n","  <center>[LeNet-5 구조]</center>\n","\n","  <sub>출처: https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4</sub>"]},{"cell_type":"markdown","metadata":{"id":"SBSS3kYSeBNA"},"source":["## AlexNet\n","\n","- 활성화 함수로 **ReLU** 사용\n","\n","- 국소적 정규화(Local Response normalization, LRN) 실시하는 계층 사용\n","\n","- 드롭아웃\n","\n","  <img src=\"https://miro.medium.com/proxy/1*qyc21qM0oxWEuRaj-XJKcw.png\" width=\"800\">\n","\n","  <center>[AlexNet 구조]</center>\n","\n","  <sub>출처: http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf</sub>"]},{"cell_type":"markdown","metadata":{"id":"MTxvT4A4d_AF"},"source":["## VGG - 16\n","\n","- 모든 컨볼루션 레이어에서의 필터(커널) 사이즈를 **3x3**으로 설정\n","\n","- 2x2 MaxPooling\n","\n","- 필터의 개수는 Conv Block을 지나가면서 2배씩 증가  \n","  32 -> 64 -> 128\n","\n","  <br>\n","\n","  <img src=\"https://www.researchgate.net/profile/Jose_Cano31/publication/327070011/figure/fig1/AS:660549306159105@1534498635256/VGG-16-neural-network-architecture.png\" width=\"800\">\n","\n","  <center>[VGG-16 구조]</center>\n","\n","  <sub>출처: Very Deep Convolutional Networks for Large-Scale Image Recognition</sub>"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"_10 CNN.ipynb","provenance":[{"file_id":"1xhL09gss_KwPwJkYf2iBxg4zbuJe_XIE","timestamp":1634276915811}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
